WHERE IS INDEXED INFORMATION STORED?
====================================

Your indexed information is stored IN-MEMORY in Python data structures 
within the TravelSpotIndexer class. It's NOT permanently saved to disk.

Location: src/indexer.py → TravelSpotIndexer.__init__()

═════════════════════════════════════════════════════════════════════════════

1. PRIMARY DATA STRUCTURES
═════════════════════════════════════════════════════════════════════════════

In the TravelSpotIndexer object, 7 key attributes store all indexed data:

┌─────────────────────────────────────────────────────────────────────────┐
│ ATTRIBUTE NAME          │ TYPE              │ CONTENT                   │
├─────────────────────────────────────────────────────────────────────────┤
│ 1. spots_data           │ List[Dict]        │ Raw JSON data from file   │
│    [★ PRIMARY]          │                   │ All 25 destinations       │
├─────────────────────────────────────────────────────────────────────────┤
│ 2. inverted_index       │ Dict[term, Set]   │ term → spot IDs           │
│    [★ CORE]             │                   │ For keyword search        │
├─────────────────────────────────────────────────────────────────────────┤
│ 3. spot_metadata        │ Dict[id, Dict]    │ Cached metadata per spot  │
│    [★ CORE]             │                   │ For fast retrieval        │
├─────────────────────────────────────────────────────────────────────────┤
│ 4. mood_index           │ Dict[mood, Set]   │ mood → spot IDs           │
│                         │                   │ For mood-based queries    │
├─────────────────────────────────────────────────────────────────────────┤
│ 5. doc_frequencies      │ Dict[term, int]   │ term → count of docs      │
│                         │                   │ Used for IDF calculation  │
├─────────────────────────────────────────────────────────────────────────┤
│ 6. _idf_cache           │ Dict[term, float] │ term → IDF score          │
│                         │                   │ Performance optimization  │
├─────────────────────────────────────────────────────────────────────────┤
│ 7. total_docs           │ int               │ Total # of destinations   │
│                         │                   │ Currently: 25             │
└─────────────────────────────────────────────────────────────────────────┘

═════════════════════════════════════════════════════════════════════════════

2. DETAILED STRUCTURE OF EACH INDEX
═════════════════════════════════════════════════════════════════════════════

A) spots_data (List of 25 dicts)
──────────────────────────────────

spots_data = [
    {
        'id': 1,
        'name': 'Goa Beach',
        'mood': ['relaxing', 'party'],
        'budget_min': 2500,
        'budget_max': 6000,
        'duration_days': 4,
        'distance_km': 1500,
        'rating': 4.5,
        'best_months': ['october', 'november', ...],
        'description': 'Goa Beach is India\'s premier coastal paradise...'
    },
    {
        'id': 2,
        'name': 'Manali Hill Station',
        'mood': ['adventure', 'nature'],
        ...
    },
    ... (23 more destinations)
]

Storage: RAM (Python list in memory)
Loaded from: data/travel_spots.json
Access: indexer.spots_data[0] → First destination


B) inverted_index (Dict[str, Set[int]])
────────────────────────────────────────

Mapping: term → set of spot IDs containing that term

Example:

inverted_index = {
    'beach': {1, 3, 10, 14, 17, 25},           # 6 spots mention "beach"
    'goa': {1},                                 # Only spot 1 mentions "goa"
    'mountain': {2, 5, 9, 18, 20},             # 5 spots mention "mountain"
    'spiritual': {7, 11},                       # 2 spots mention "spiritual"
    'adventure': {2, 5, 9, 18, 20},            # 5 spots tagged "adventure"
    'relaxing': {1, 3, 6, 10, 14},             # 5 spots tagged "relaxing"
    'temple': {7, 11},
    'river': {7, 10},
    'palace': {12, 13, 24},
    ... (thousands of terms)
}

Storage: RAM (Python dict with defaultdict(set))
Built by: build_index() → tokenizes all text → populates this
Access: indexer.inverted_index['beach'] → {1, 3, 10, 14, 17, 25}


C) spot_metadata (Dict[int, Dict])
───────────────────────────────────

Mapping: spot_id → extracted metadata (fast cache)

Example:

spot_metadata = {
    1: {
        'name': 'Goa Beach',
        'mood': ['relaxing', 'party'],
        'budget_min': 2500,
        'budget_max': 6000,
        'duration_days': 4,
        'distance_km': 1500,
        'rating': 4.5,
        'description': 'Goa Beach is India\'s premier coastal paradise...',
        'best_months': ['october', 'november', 'december', ...]
    },
    2: {
        'name': 'Manali Hill Station',
        ...
    },
    ... (25 entries total)
}

Storage: RAM (Python dict)
Purpose: Cache metadata for O(1) lookup during ranking
Access: indexer.spot_metadata[1] → metadata for "Goa Beach"
        indexer.get_spot_by_id(1) → same thing


D) mood_index (Dict[str, Set[int]])
────────────────────────────────────

Mapping: mood → set of spot IDs with that mood

Example:

mood_index = {
    'adventure': {2, 5, 9, 18, 20},
    'nature': {2, 5, 9, 14, 15, 18, 20, 23},
    'relaxing': {1, 3, 6, 10, 14, 15},
    'party': {1, 8},
    'cultural': {4, 12, 13, 16, 19, 21, 22},
    'history': {4, 12, 13, 19, 21, 22},
    'spiritual': {7, 10, 11},
    'romantic': {3, 17, 24, 25},
    ... (one entry per unique mood)
}

Storage: RAM (Python dict with defaultdict(set))
Built by: build_index() → adds spot_id for each mood
Access: indexer.mood_index['adventure'] → {2, 5, 9, 18, 20}
        indexer.get_spots_by_mood('adventure') → same


E) doc_frequencies (Dict[str, int])
────────────────────────────────────

Mapping: term → number of documents (spots) containing it

Example:

doc_frequencies = {
    'beach': 6,            # "beach" appears in 6 documents
    'goa': 1,              # "goa" appears in 1 document
    'mountain': 5,         # "mountain" appears in 5 documents
    'spiritual': 2,        # "spiritual" appears in 2 documents
    'temple': 2,
    'river': 3,
    'palace': 3,
    'india': 25,           # "india" appears in all 25 documents
    ... (thousands of terms)
}

Storage: RAM (Python dict with defaultdict(int))
Used by: calculate_idf() → IDF = log(total_docs / doc_frequencies[term])
Access: indexer.doc_frequencies['beach'] → 6


F) _idf_cache (Dict[str, float])
─────────────────────────────────

Mapping: term → pre-calculated IDF score (cache for performance)

Example:

_idf_cache = {
    'beach': 1.427,        # log(25/6) ≈ 1.427
    'goa': 3.219,          # log(25/1) ≈ 3.219 (rare!)
    'mountain': 1.609,     # log(25/5) ≈ 1.609
    'spiritual': 2.525,    # log(25/2) ≈ 2.525
    'india': 0.0,          # log(25/25) = 0.0 (common everywhere)
    ... (only includes calculated terms)
}

Storage: RAM (Python dict)
Populated by: calculate_idf() on first call
Purpose: O(1) lookup instead of recalculating log() every time
Access: indexer._idf_cache['beach'] → 1.427


G) Other attributes
────────────────────

total_docs: 25 (integer)
dataset_path: "data/travel_spots.json" (string)

═════════════════════════════════════════════════════════════════════════════

3. DATA FLOW: FROM FILE TO INDEXED STRUCTURES
═════════════════════════════════════════════════════════════════════════════

Step 1: LOAD (load_dataset)
─────────────────────────────
    data/travel_spots.json
           ↓
    JSON → Python dict → self.spots_data (List)
    
    travel_spots.json contains:
    {
        "travel_spots": [
            {"id": 1, "name": "Goa Beach", ...},
            {"id": 2, "name": "Manali Hill Station", ...},
            ...
        ]
    }
    
    Result: spots_data now contains all 25 destinations


Step 2: BUILD INDEX (build_index)
──────────────────────────────────
    self.spots_data
           ↓
    For each spot:
    ├─ Extract: name + description
    ├─ Tokenize: → ['word1', 'word2', ...]
    ├─ Build inverted_index: term → spot_id
    ├─ Build mood_index: mood → spot_id
    ├─ Track doc_frequencies: term → count
    ├─ Cache spot_metadata: spot_id → data
    └─ Set total_docs = 25
    
    Result: All 6 indexes are populated


Step 3: USE (during search/ranking)
────────────────────────────────────
    User Query: "best beach for 4 days"
           ↓
    Query Processor extracts:
    ├─ query_terms: ['beach', 'days']
    ├─ duration_days: 4
    └─ ...
           ↓
    Ranker scores each destination:
    ├─ inverted_index['beach'] → spot_ids {1,3,10,14,17,25}
    ├─ _idf_cache['beach'] → 1.427
    ├─ spot_metadata[1] → name, budget, duration, etc.
    ├─ mood_index lookup → related moods
    └─ Calculate relevance score
           ↓
    Ranked results returned to user

═════════════════════════════════════════════════════════════════════════════

4. MEMORY BREAKDOWN (APPROXIMATE)
═════════════════════════════════════════════════════════════════════════════

Assuming 25 destinations with average 2KB description each:

Structure              │ Size (Approx)  │ Count
────────────────────────┼────────────────┼──────────
spots_data             │ ~100 KB        │ 25 dicts
inverted_index         │ ~150 KB        │ 5,000 terms
spot_metadata          │ ~50 KB         │ 25 dicts
mood_index             │ ~2 KB          │ 8-10 moods
doc_frequencies        │ ~50 KB         │ 5,000 terms
_idf_cache             │ ~50 KB         │ terms with calculated IDF
────────────────────────┼────────────────┼──────────
TOTAL                  │ ~400 KB        │ IN MEMORY

This is very efficient! All in RAM means microsecond lookups.

═════════════════════════════════════════════════════════════════════════════

5. WHEN IS IT CREATED/DESTROYED?
═════════════════════════════════════════════════════════════════════════════

Creation:
─────────
1. Server starts → recommendation_system.py
2. Initializes: indexer = TravelSpotIndexer()
   └─ Empty indexes created
3. Calls: indexer.load_dataset('data/travel_spots.json')
   └─ spots_data populated from JSON file
4. Calls: indexer.build_index()
   └─ All 6 indexes populated & cached
5. Life: Remains in memory for entire server session
   └─ Fast lookups for all queries

Destruction:
────────────
• Server stops/crashes
• Python process terminates
• All in-memory data is lost
• NO persistent storage!

⚠️  IMPORTANT: If you restart the server, the index is rebuilt from scratch
    by reloading data/travel_spots.json


6. HOW TO ACCESS THE INDEXED DATA
═════════════════════════════════════════════════════════════════════════════

From Python code:

# Direct access
indexer.inverted_index['beach']          # → {1, 3, 10, 14, 17, 25}
indexer.spot_metadata[1]                 # → {...metadata...}
indexer.mood_index['adventure']          # → {2, 5, 9, 18, 20}
indexer.doc_frequencies['beach']         # → 6
indexer._idf_cache['beach']              # → 1.427
indexer.total_docs                       # → 25

# Through methods
indexer.get_spot_by_id(1)                # → spot metadata
indexer.get_spots_by_mood('adventure')   # → {2, 5, 9, 18, 20}
indexer.calculate_idf('beach')           # → 1.427 (uses cache)
indexer.get_indexed_spots()              # → all 25 metadata dicts


7. SUMMARY
══════════════════════════════════════════════════════════════════════════════

WHERE:    RAM memory (in-process Python objects)
          Specifically in TravelSpotIndexer instance variables

WHAT:     6 indexes + 25 destination records
          ~400 KB total size

HOW:      Loaded from data/travel_spots.json on server startup
          Built/cached during build_index() phase

WHY:      Fast O(1) lookups for real-time search & ranking
          No disk I/O needed for queries

LIFETIME: From server start to server stop
          Rebuilt on each restart
